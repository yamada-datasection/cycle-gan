{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1159ae8f0>"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    \n",
    "    def __init__(self):\n",
    "        base_dir = os.getcwd()\n",
    "        self.train_X = self.img_to_npy(os.path.join(base_dir, 'emojis/Apple/Appl/*.png'))\n",
    "        self.train_Y = self.img_to_npy(os.path.join(base_dir, 'emojis/Windows/Wind./*.png'))\n",
    "        self.test_X = self.img_to_npy(os.path.join(base_dir, 'emojis/Test_Apple/Appl/*.png'))\n",
    "        self.test_Y = self.img_to_npy(os.path.join(base_dir, 'emojis/Test_Windows/Wind/*.png'))\n",
    "    \n",
    "    def getTrainX(self, minibatch_size):    \n",
    "        return self.getData(minibatch_size, self.train_X)\n",
    "    \n",
    "    def getTrainY(self, minibatch_size):\n",
    "        return self.getData(minibatch_size, self.train_Y)\n",
    "    \n",
    "    def getTestX(self, minibatch_size):\n",
    "        return self.getData(minibatch_size, self.test_X)\n",
    "    \n",
    "    def getTestY(self, minibatch_size):\n",
    "        return self.getData(minibatch_size, self.test_Y)\n",
    "\n",
    "    def getData(self, minibatch_size, npy_data):\n",
    "        minibatch_npy_data = np.random.permutation(npy_data)[:minibatch_size]\n",
    "        minibatch_tensor_data = torch.from_numpy(minibatch_npy_data)\n",
    "        \n",
    "        return minibatch_tensor_data\n",
    "    \n",
    "    def img_to_npy(self, path):\n",
    "        img_array = np.ones((1, 72, 72, 3))\n",
    "\n",
    "        img_list = glob.glob(path)\n",
    "\n",
    "        for img_path in img_list:\n",
    "            new_img = Image.open(img_path).convert('RGBA')\n",
    "            new_img_array = np.array(new_img)[np.newaxis, :, :, :3]\n",
    "            img_array = np.concatenate([img_array, new_img_array], axis=0)\n",
    "        img_array = img_array[1:]\n",
    "        \n",
    "        return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderNpy():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_X = np.load(\"emojis_npy/train_X.npy\")\n",
    "        self.train_Y = np.load(\"emojis_npy/train_Y.npy\")\n",
    "        self.test_X = np.load(\"emojis_npy/test_X.npy\")\n",
    "        self.test_Y = np.load(\"emojis_npy/test_Y.npy\")\n",
    "        \n",
    "    def getTrainX(self, minibatch_size):    \n",
    "        return self.getData(minibatch_size, self.train_X)\n",
    "    \n",
    "    def getTrainY(self, minibatch_size):\n",
    "        return self.getData(minibatch_size, self.train_Y)\n",
    "    \n",
    "    def getTestX(self, minibatch_size):\n",
    "        return self.getData(minibatch_size, self.test_X)\n",
    "    \n",
    "    def getTestY(self, minibatch_size):\n",
    "        return self.getData(minibatch_size, self.test_Y)\n",
    "\n",
    "    def getData(self, minibatch_size, npy_data):\n",
    "        npy_data = npy_data.astype(np.float32)\n",
    "        minibatch_npy_data = np.random.permutation(npy_data)[:minibatch_size]\n",
    "        minibatch_npy_data = minibatch_npy_data.transpose(0, 3, 1, 2)\n",
    "        minibatch_tensor_data = torch.from_numpy(minibatch_npy_data)\n",
    "        \n",
    "        return minibatch_tensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, conv_dim):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_layer = nn.Conv2d(conv_dim, conv_dim, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, conv_dim=32):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, conv_dim, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(conv_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(conv_dim, conv_dim*2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(conv_dim*2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(conv_dim*2, conv_dim*4, kernel_size=4, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(conv_dim*4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            ResidualBlock(conv_dim*4),\n",
    "            nn.BatchNorm2d(conv_dim*4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(conv_dim*4, conv_dim*2, kernel_size=4, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(conv_dim*2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(conv_dim*2, conv_dim, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(conv_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.last = nn.Sequential(\n",
    "            nn.ConvTranspose2d(conv_dim, 3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.last(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, conv_dim=32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, conv_dim, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(conv_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(conv_dim, conv_dim*2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(conv_dim*2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(conv_dim*2, conv_dim*4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(conv_dim*4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(conv_dim*4, conv_dim*8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(conv_dim*8),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.last = nn.Sequential(\n",
    "            nn.Conv2d(conv_dim*8, 1, kernel_size=4, stride=2, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.last(out)\n",
    "        out = out.squeeze()\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "F = Generator()\n",
    "Dx = Discriminator()\n",
    "Dy = Discriminator()\n",
    "\n",
    "data_loader = DataLoaderNpy()\n",
    "x_sample = data_loader.getTrainX(minibatch_size)\n",
    "y_sample = data_loader.getTrainY(minibatch_size)\n",
    "\n",
    "mse_loss = nn.MSELoss(reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop():\n",
    "    \n",
    "    minibatch_size = 32\n",
    "    conv_dim = 32\n",
    "    \n",
    "    g_lr, d_lr = 0.0001, 0.0004\n",
    "    beta1, beta2 = 0.0, 0.9\n",
    "    \n",
    "    G = Generator()\n",
    "    F = Generator()\n",
    "    Dx = Discriminator()\n",
    "    Dy = Discriminator()\n",
    "    \n",
    "    data_loader = DataLoaderNpy()\n",
    "    print(\"Initialized\")\n",
    "\n",
    "    g_params = list(G.parameters()) + list(F.parameters())\n",
    "    d_params = list(Dx.parameters()) + list(Dy.parameters())\n",
    "    \n",
    "    mse_loss = nn.MSELoss(reduction=\"mean\")\n",
    "    \n",
    "    for i in range(100):\n",
    "        print(i)\n",
    "        #sampling\n",
    "        x_sample = data_loader.getTrainX(minibatch_size)\n",
    "        y_sample = data_loader.getTrainY(minibatch_size)\n",
    "\n",
    "        #train D with real images for \n",
    "        d_optimizer.zero_grad()\n",
    "\n",
    "        d_real_loss = mse_loss(Dx(x_sample), torch.full((minibatch_size, ), 1)) + mse_loss(Dy(y_sample), torch.full((minibatch_size, ), 1))\n",
    "        d_real_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        #train D with fake images \n",
    "        d_optimizer.zero_grad()\n",
    "\n",
    "        d_fake_loss = mse_loss(Dy(G(x_sample)), torch.full((minibatch_size, ), 0)) + mse_loss(Dx(F(y_sample)), torch.full((minibatch_size, ), 0))\n",
    "        d_fake_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        #train G with X--Y-->X cycle\n",
    "        g_optimizer.zero_grad()\n",
    "\n",
    "        g_loss = mse_loss(Dx(F(y_sample)), torch.full((minibatch_size, ), 1)) + mse_loss(y_sample, G(F(y_sample)))\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        #train G with Y--X-->Y cycle\n",
    "        d_optimizer.zero_grad()\n",
    "\n",
    "        f_loss = mse_loss(Dy(G(x_sample)), torch.full((minibatch_size, ), 1)) + mse_loss(x_sample, F(G(x_sample)))\n",
    "        f_loss.backward()\n",
    "        g_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-406-191ba6fad27d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-405-c9291ee676a2>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mg_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
